{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, explode, array, lit\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import LogisticRegression,OneVsRest\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import dayofweek\n",
    "from pyspark.sql.functions import isnan, when, count, col, lit, sum\n",
    "from pyspark.sql.functions import (to_date, datediff, date_format,month)\n",
    "#Este es un comentario\n",
    "#Se carga el conjunto de datos\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Avila\").config(\"spark.some.config.option\",\"some-value\").getOrCreate()\n",
    "data = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\", \"true\").load(r\"avila.csv\")\n",
    "\n",
    "#####################################################################################################\n",
    "#PRIMER PUNTO\n",
    "#DESCRIPCION DEL CONJUNTO DE DATOS INICIAL\n",
    "#Imprime la cantidad de registros y atributos respectivamente\n",
    "print(\"Registros Iniciales:\",data.count(),\", Atributos Iniciales:\",len(data.columns))\n",
    "\n",
    "#Tipo de los atributos\n",
    "data.printSchema()\n",
    "\n",
    "# Se revisa si existen nulos en alguno de los atributos del dataset\n",
    "print(\"Cantidad de Nulos en cada atributo\")\n",
    "print(data.select([count(when(isnan(c),c)).alias(c) for c in data.columns]).toPandas().head())\n",
    "\n",
    "#Descripcion de los atributos\n",
    "print(\"Descripcion de los atributos\")\n",
    "print(data.describe().select(\"Summary\",\"F1\",\"F2\",\"F3\",\"F4\",\"F5\").show())\n",
    "print(data.describe().select(\"Summary\",\"F6\",\"F7\",\"F8\",\"F9\",\"F10\").show())\n",
    "\n",
    "#Se verifica la correlacion entre los atributos\n",
    "pd = data.toPandas()\n",
    "print(\"Correlacion entre atributos\")\n",
    "print(pd.corr())\n",
    "\n",
    "\n",
    "#Distribucion del atributo clasificador\n",
    "print(\"Distribucion del atributo clasificador\")\n",
    "data.groupby(\"Author\").count().show()\n",
    "#####################################################################################################\n",
    "#COMIENZA EL SEGUNDO PUNTO\n",
    "#LIMPIEZA DE LOS DATOS\n",
    "\n",
    "#Como se puede ver en los diagramas de cajas, el atributo F2 tiene datos que son demasiado atipicos\n",
    "#Estos registros se eliminaran\n",
    "print(\"LIMPIEZA DE LOS DATOS\")\n",
    "data = data.filter(data.F2<350)\n",
    "print(\"Datos Demasiado Atipicos de F2 Eliminados:\",data.count())\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(\"Conversion de atributos categoricos a numericos\")\n",
    "indexer = StringIndexer(inputCol=\"Author\", outputCol=\"AuthorNum\")\n",
    "data = indexer.fit(data).transform(data)\n",
    "data = data.drop('Author')\n",
    "data.groupby(\"AuthorNum\").count().show()\n",
    "\n",
    "\n",
    "\n",
    "#Se balancea cada categoria\n",
    "\n",
    "A = data.filter(data.AuthorNum == 0.0).sample(fraction=0.24)\n",
    "F = data.filter(data.AuthorNum == 1.0).sample(fraction=0.53)\n",
    "E = data.filter(col(\"AuthorNum\") == 2.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(1)]))).drop('dummy')\n",
    "I = data.filter(col(\"AuthorNum\") == 3.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(1)]))).drop('dummy')\n",
    "X = data.filter(col(\"AuthorNum\") == 4.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(2)]))).drop('dummy')\n",
    "H = data.filter(col(\"AuthorNum\") == 5.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(2)]))).drop('dummy')\n",
    "G = data.filter(col(\"AuthorNum\") == 6.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(2)]))).drop('dummy')\n",
    "D = data.filter(col(\"AuthorNum\") == 7.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(3)]))).drop('dummy')\n",
    "Y = data.filter(col(\"AuthorNum\") == 8.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(4)]))).drop('dummy')\n",
    "C = data.filter(col(\"AuthorNum\") == 9.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(8)]))).drop('dummy')\n",
    "W = data.filter(col(\"AuthorNum\") == 10.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(17)]))).drop('dummy')\n",
    "B = data.filter(col(\"AuthorNum\") == 11.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(170)]))).drop('dummy')\n",
    "\n",
    "#Se juntan todas las categorias balanceadas\n",
    "data = A.union(B).union(C).union(D).union(E).union(F).union(G).union(H).union(I).union(W).union(Y).union(X)\n",
    "\n",
    "print(\"Conjunto Balanceado\")\n",
    "data.groupby(\"AuthorNum\").count().show()\n",
    "print(\"Numero de Registros Dataset Limpio:\",data.count(),\", Atributos:\",len(data.columns))\n",
    "\n",
    "#####################################################################################################\n",
    "#COMIENZA PUNTO 3\n",
    "#Entrenamiento de modelos:\n",
    "#Modelo 1\n",
    "\n",
    "cols=data.columns\n",
    "cols.remove(\"AuthorNum\")\n",
    "\n",
    "assembler = VectorAssembler(inputCols=cols,outputCol=\"features\")\n",
    "data=assembler.transform(data)\n",
    "train, test = data.randomSplit([0.8, 0.2],seed=20)\n",
    "\n",
    "\n",
    "lr = LogisticRegression(labelCol=\"AuthorNum\",maxIter=1000,featuresCol=\"features\",family=\"multinomial\",elasticNetParam=0.8)\n",
    "\n",
    "# Fit the model\n",
    "lrModel = lr.fit(train)\n",
    "predict_test=lrModel.transform(test)\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"AuthorNum\",\tpredictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "lr_accuracy = evaluator.evaluate(predict_test)\n",
    "print(\"Accuracy score of LogisticRegression is = {}\".format(lr_accuracy))\n",
    "\n",
    "\n",
    "\n",
    "#Modelo 2\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "\n",
    "dt = DecisionTreeClassifier(labelCol=\"AuthorNum\", featuresCol=\"features\",maxDepth=20)\n",
    "dt_model = dt.fit(train)\n",
    "dt_prediction = dt_model.transform(test)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"AuthorNum\",predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "dt_accuracy = evaluator.evaluate(dt_prediction)\n",
    "print(\"Accuracy Score of DecisionTreeClassifier is = {}\" .format(dt_accuracy))\n",
    "#Random forest\n",
    "\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "\n",
    "\n",
    "rf = RandomForestClassifier(labelCol=\"AuthorNum\", featuresCol=\"features\",numTrees=10,subsamplingRate=1,maxDepth=20)\n",
    "rf_model = rf.fit(train)\n",
    "rf_prediction = rf_model.transform(test)\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(labelCol=\"AuthorNum\",\n",
    "                                              predictionCol=\"prediction\", metricName=\"accuracy\")\n",
    "\n",
    "rf_accuracy = evaluator.evaluate(rf_prediction)\n",
    "print(\"Accuracy Score of RandomForestClassifier is = {}\".format(rf_accuracy))\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
