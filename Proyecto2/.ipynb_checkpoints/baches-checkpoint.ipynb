{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Registros Iniciales: 20867 , Atributos Iniciales: 11\n",
      "root\n",
      " |-- F1: double (nullable = true)\n",
      " |-- F2: double (nullable = true)\n",
      " |-- F3: double (nullable = true)\n",
      " |-- F4: double (nullable = true)\n",
      " |-- F5: double (nullable = true)\n",
      " |-- F6: double (nullable = true)\n",
      " |-- F7: double (nullable = true)\n",
      " |-- F8: double (nullable = true)\n",
      " |-- F9: double (nullable = true)\n",
      " |-- F10: double (nullable = true)\n",
      " |-- Author: string (nullable = true)\n",
      "\n",
      "Cantidad de Nulos en cada atributo\n",
      "   F1  F2  F3  F4  F5  F6  F7  F8  F9  F10  Author\n",
      "0   0   0   0   0   0   0   0   0   0    0       0\n",
      "Descripcion de los atributos\n",
      "+-------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "|Summary|                  F1|                 F2|                  F3|                  F4|                  F5|\n",
      "+-------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "|  count|               20867|              20867|               20867|               20867|               20867|\n",
      "|   mean|-3.30665647008743...|0.01849807293813218|0.002328867398284...|1.154239229405380...|5.697992049061326E-8|\n",
      "| stddev|  1.0000072509694418|  2.853116758649088|  1.0582030864294198|  0.9999974852633741|  0.9999948173431626|\n",
      "|    min|           -3.498799|          -2.426761|           -3.210528|           -5.440122|           -4.922215|\n",
      "|    max|           11.819916|              386.0|                50.0|            3.987152|            1.066121|\n",
      "+-------+--------------------+-------------------+--------------------+--------------------+--------------------+\n",
      "\n",
      "None\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "|Summary|                  F6|                  F7|                  F8|                  F9|                F10|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "|  count|               20867|               20867|               20867|               20867|              20867|\n",
      "|   mean|0.002539710356064...|0.003977167776872577|2.816657880866039E-5|0.002108021948531...|6.93842430632189E-5|\n",
      "| stddev|  1.0651787221451638|    1.15332490347375|   1.000003117638661|  1.0453623588623464| 1.0000098794516241|\n",
      "|    min|           -7.450257|          -11.935457|           -4.247781|           -5.486218|          -6.719324|\n",
      "|    max|                53.0|                83.0|           13.173081|                44.0|          11.911338|\n",
      "+-------+--------------------+--------------------+--------------------+--------------------+-------------------+\n",
      "\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import isnan, when, count, col, explode, array, lit\n",
    "from pyspark.ml.feature import StringIndexer\n",
    "from pyspark.ml.feature import Imputer\n",
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "\n",
    "\n",
    "from pyspark.ml.feature import StandardScaler\n",
    "from pyspark.ml.feature import ChiSqSelector\n",
    "from pyspark.mllib.evaluation import MulticlassMetrics\n",
    "from pyspark.sql.types import FloatType\n",
    "from pyspark.ml.classification import LinearSVC\n",
    "from pyspark.ml.classification import LogisticRegression,OneVsRest\n",
    "from pyspark.ml.evaluation import BinaryClassificationEvaluator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "from pyspark.sql.functions import dayofweek\n",
    "from pyspark.ml.classification import DecisionTreeClassifier\n",
    "from pyspark.ml.classification import RandomForestClassifier\n",
    "from pyspark.sql.functions import isnan, when, count, col, lit, sum\n",
    "from pyspark.sql.functions import (to_date, datediff, date_format,month)\n",
    "#Se carga el conjunto de datos\n",
    "\n",
    "spark = SparkSession.builder.master(\"local\").appName(\"Avila\").config(\"spark.some.config.option\",\"some-value\").getOrCreate()\n",
    "data = spark.read.format(\"csv\").option(\"header\",\"true\").option(\"inferSchema\", \"true\").load(r\"avila.csv\")\n",
    "\n",
    "#####################################################################################################\n",
    "#PRIMER PUNTO\n",
    "#DESCRIPCION DEL CONJUNTO DE DATOS INICIAL\n",
    "#Imprime la cantidad de registros y atributos respectivamente\n",
    "print(\"Registros Iniciales:\",data.count(),\", Atributos Iniciales:\",len(data.columns))\n",
    "\n",
    "#Tipo de los atributos\n",
    "data.printSchema()\n",
    "\n",
    "# Se revisa si existen nulos en alguno de los atributos del dataset\n",
    "print(\"Cantidad de Nulos en cada atributo\")\n",
    "print(data.select([count(when(isnan(c),c)).alias(c) for c in data.columns]).toPandas().head())\n",
    "\n",
    "#Descripcion de los atributos\n",
    "print(\"Descripcion de los atributos\")\n",
    "print(data.describe().select(\"Summary\",\"F1\",\"F2\",\"F3\",\"F4\",\"F5\").show())\n",
    "print(data.describe().select(\"Summary\",\"F6\",\"F7\",\"F8\",\"F9\",\"F10\").show())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distribucion del atributo clasificador\n",
      "+------+-----+\n",
      "|Author|count|\n",
      "+------+-----+\n",
      "|     F| 3923|\n",
      "|     E| 2190|\n",
      "|     B|   10|\n",
      "|     Y|  533|\n",
      "|     D|  705|\n",
      "|     C|  206|\n",
      "|     A| 8572|\n",
      "|     X| 1044|\n",
      "|     W|   89|\n",
      "|     G|  893|\n",
      "|     I| 1663|\n",
      "|     H| 1039|\n",
      "+------+-----+\n",
      "\n",
      "LIMPIEZA DE LOS DATOS\n",
      "Datos Demasiado Atipicos de F2 Eliminados: 20866\n",
      "Conversion de atributos categoricos a numericos\n",
      "+---------+-----+\n",
      "|AuthorNum|count|\n",
      "+---------+-----+\n",
      "|      8.0|  533|\n",
      "|      0.0| 8571|\n",
      "|      7.0|  705|\n",
      "|      1.0| 3923|\n",
      "|      4.0| 1044|\n",
      "|     11.0|   10|\n",
      "|      3.0| 1663|\n",
      "|      2.0| 2190|\n",
      "|     10.0|   89|\n",
      "|      6.0|  893|\n",
      "|      5.0| 1039|\n",
      "|      9.0|  206|\n",
      "+---------+-----+\n",
      "\n",
      "Conjunto Balanceado\n",
      "+---------+-----+\n",
      "|AuthorNum|count|\n",
      "+---------+-----+\n",
      "|      8.0| 2132|\n",
      "|      0.0| 6627|\n",
      "|      7.0| 2115|\n",
      "|      4.0| 2088|\n",
      "|     11.0| 1700|\n",
      "|      3.0| 1663|\n",
      "|      2.0| 2190|\n",
      "|     10.0| 1513|\n",
      "|      6.0| 1786|\n",
      "|      5.0| 2078|\n",
      "|      9.0| 1648|\n",
      "+---------+-----+\n",
      "\n",
      "Numero de Registros Dataset Limpio: 25540 , Atributos: 11\n"
     ]
    }
   ],
   "source": [
    "#Se verifica la correlacion entre los atributos\n",
    "#pd = data.toPandas()\n",
    "#print(\"Correlacion entre atributos\")\n",
    "#print(pd.corr())\n",
    "\n",
    "#Distribucion del atributo clasificador\n",
    "print(\"Distribucion del atributo clasificador\")\n",
    "data.groupby(\"Author\").count().show()\n",
    "#####################################################################################################\n",
    "#COMIENZA EL SEGUNDO PUNTO\n",
    "#LIMPIEZA DE LOS DATOS\n",
    "\n",
    "#Como se puede ver en los diagramas de cajas, el atributo F2 tiene datos que son demasiado atipicos\n",
    "#Estos registros se eliminaran\n",
    "print(\"LIMPIEZA DE LOS DATOS\")\n",
    "data = data.filter(data.F2<350)\n",
    "print(\"Datos Demasiado Atipicos de F2 Eliminados:\",data.count())\n",
    "\n",
    "print(\"Conversion de atributos categoricos a numericos\")\n",
    "indexer = StringIndexer(inputCol=\"Author\", outputCol=\"AuthorNum\")\n",
    "data = indexer.fit(data).transform(data)\n",
    "data = data.drop('Author')\n",
    "data.groupby(\"AuthorNum\").count().show()\n",
    "\n",
    "#Se balancea cada categoria (Entre 1000 y 2000 atributos cada una)\n",
    "A = data.filter(data.AuthorNum == 0.0).sample(fraction=0.24)\n",
    "F = data.filter(data.AuthorNum == 0.0).sample(fraction=0.53)\n",
    "E = data.filter(col(\"AuthorNum\") == 2.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(1)]))).drop('dummy')\n",
    "I = data.filter(col(\"AuthorNum\") == 3.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(1)]))).drop('dummy')\n",
    "X = data.filter(col(\"AuthorNum\") == 4.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(2)]))).drop('dummy')\n",
    "H = data.filter(col(\"AuthorNum\") == 5.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(2)]))).drop('dummy')\n",
    "G = data.filter(col(\"AuthorNum\") == 6.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(2)]))).drop('dummy')\n",
    "D = data.filter(col(\"AuthorNum\") == 7.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(3)]))).drop('dummy')\n",
    "Y = data.filter(col(\"AuthorNum\") == 8.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(4)]))).drop('dummy')\n",
    "C = data.filter(col(\"AuthorNum\") == 9.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(8)]))).drop('dummy')\n",
    "W = data.filter(col(\"AuthorNum\") == 10.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(17)]))).drop('dummy')\n",
    "B = data.filter(col(\"AuthorNum\") == 11.0).withColumn(\"dummy\", explode(array([lit(x) for x in range(170)]))).drop('dummy')\n",
    "\n",
    "#Se juntan todas las categorias balanceadas\n",
    "data = A.union(B).union(C).union(D).union(E).union(F).union(G).union(H).union(I).union(W).union(Y).union(X)\n",
    "\n",
    "print(\"Conjunto Balanceado\")\n",
    "data.groupby(\"AuthorNum\").count().show()\n",
    "print(\"Numero de Registros Dataset Limpio:\",data.count(),\", Atributos:\",len(data.columns))\n",
    "\n",
    "\n",
    "\n",
    "#####################################################################################################\n",
    "#COMIENZA PUNTO 3\n",
    "#Entrenamiento de modelos:\n",
    "cols=data.columns\n",
    "cols.remove(\"AuthorNum\")\n",
    "assembler = VectorAssembler(inputCols=cols,outputCol=\"features\")\n",
    "\n",
    "\n",
    "#Se crea el conjunto de entrenamiento y test\n",
    "train, test = data.randomSplit([0.7, 0.3],seed=20)\n",
    "#train=assembler.transform(train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ENTRENAMIENTO:\n",
      "Numero de Registros Train: 17807 , Atributos: ['F1', 'F2', 'F3', 'F4', 'F5', 'F6', 'F7', 'F8', 'F9', 'F10', 'AuthorNum', 'features']\n",
      "TEST:\n",
      "Numero de Registros Test: 7812 , Atributos: 11\n"
     ]
    }
   ],
   "source": [
    "print(\"ENTRENAMIENTO:\")\n",
    "print(\"Numero de Registros Train:\",train.count(),\", Atributos:\",train.columns)\n",
    "print(\"TEST:\")\n",
    "print(\"Numero de Registros Test:\",test.count(),\", Atributos:\",len(test.columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creación baches\n",
    "num_baches = 4\n",
    "div = 1/num_baches\n",
    "df1,df2,df3,df4 = test.randomSplit([div,div,div,div],seed=20)\n",
    "df1.toPandas().to_csv('test/1.csv',index=False)\n",
    "df2.toPandas().to_csv('test/2.csv',index=False) \n",
    "df3.toPandas().to_csv('test/3.csv',index=False) \n",
    "df4.toPandas().to_csv('test/4.csv',index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler,VectorSizeHint\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "cols=data.columns\n",
    "cols.remove(\"AuthorNum\")\n",
    "assembler = VectorAssembler(inputCols=cols,outputCol=\"features\")\n",
    "rf = RandomForestClassifier(labelCol=\"AuthorNum\", featuresCol=\"features\",numTrees=10,subsamplingRate=1,maxDepth=20)\n",
    "pipeline = Pipeline(stages=[assembler,rf])\n",
    "\n",
    "pipelineModel = pipeline.fit(train)\n",
    "pipelineModel.write().overwrite().save(\"Spipeline\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipelineModel.write().save(\"MyPipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml import PipelineModel\n",
    "\n",
    "my_pipe = PipelineModel.load(\"Spipeline\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+---------+---------+---------+---------+---------+---------+--------+---------+---------+---------+\n",
      "|       F1|       F2|       F3|       F4|       F5|       F6|       F7|      F8|       F9|      F10|AuthorNum|\n",
      "+---------+---------+---------+---------+---------+---------+---------+--------+---------+---------+---------+\n",
      "|-3.498799|-0.573882| 0.356544| 0.750648|-4.922215| -0.10036|-0.044076|0.745124| 0.032902|  0.06106|      0.0|\n",
      "|-3.498799|-0.550328| 0.050694|-0.629422|-4.922215|-0.723232| 0.031425|0.602964|  0.40708|-0.557706|      0.0|\n",
      "|-3.498799|-0.550328| 0.050694|-0.629422|-4.922215|  0.14879| 0.635431|0.076224| 0.313536|-0.093933|      0.0|\n",
      "|-3.498799|-0.550328| 0.050694|-0.629422|-4.922215| 0.190314| 0.333428|0.287774| 0.282354| 0.105966|      0.0|\n",
      "|-3.498799|-0.440412|-3.210528|-0.364758|-4.922215| 0.356414| 0.446679|0.368232|-0.528364|  0.20131|      0.0|\n",
      "+---------+---------+---------+---------+---------+---------+---------+--------+---------+---------+---------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train.show(5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
